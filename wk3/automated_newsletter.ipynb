{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeDlZxLX9B3H"
   },
   "source": [
    "# Automated GenAI Newsletter Generator\n",
    "\n",
    "\n",
    "## Setup Environment\n",
    "Install dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7mhFQjS9B3I"
   },
   "outputs": [],
   "source": [
    "!pip install openai arxiv python-dotenv PyGithub python-pptx pandas --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mKJvJQl9B3J"
   },
   "source": [
    "## Configuration\n",
    "Enter your API keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtt9wJ4u9B3K"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "import openai\n",
    "from github import Github\n",
    "import arxiv\n",
    "\n",
    "# @title API Credentials\n",
    "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
    "github_token = userdata.get('GITHUB_TOKEN')\n",
    "email_password = userdata.get('EMAIL_PASSWORD')\n",
    "\n",
    "# Initialize clients\n",
    "github = Github(github_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1sYq5A59B3K"
   },
   "source": [
    "## Core Functions\n",
    "### 1. Content Aggregation\n",
    "Fetch research papers and GitHub repos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvE4RZ7X9B3L"
   },
   "outputs": [],
   "source": [
    "def fetch_ai_content():\n",
    "    \"\"\"Fetch latest GenAI research and projects\"\"\"\n",
    "    \n",
    "    # Get arXiv papers\n",
    "    arxiv_client = arxiv.Client()\n",
    "    search = arxiv.Search(\n",
    "        query=\"generative AI\",\n",
    "        max_results=5,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    papers = [result for result in arxiv_client.results(search)]\n",
    "\n",
    "    # Get GitHub repos\n",
    "    repos = github.search_repositories(\n",
    "        query=\"generative AI created:>2024-02-20\",\n",
    "        sort=\"updated\"\n",
    "    )[:3]\n",
    "\n",
    "    return {\n",
    "        \"papers\": papers,\n",
    "        \"repos\": repos\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wM8jKvF9B3L"
   },
   "source": [
    "### 2. AI-Powered Analysis\n",
    "Generate technical summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQc1Pq6V9B3L"
   },
   "outputs": [],
   "source": [
    "def analyze_content(content):\n",
    "    \"\"\"Process content with GPT-4\"\"\"\n",
    "    \n",
    "    # Generate paper summaries\n",
    "    paper_summaries = []\n",
    "    for paper in content['papers']:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Summarize this AI paper in 3 bullet points:\\n{paper.summary}\"\n",
    "            }],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        paper_summaries.append(response.choices[0].message.content)\n",
    "\n",
    "    # Analyze GitHub repos\n",
    "    repo_analyses = []\n",
    "    for repo in content['repos']:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Explain the technical significance of {repo.name}:\\n{repo.description}\"\n",
    "            }],\n",
    "            temperature=0.5\n",
    "        )\n",
    "        repo_analyses.append(response.choices[0].message.content)\n",
    "\n",
    "    return {\n",
    "        \"papers\": paper_summaries,\n",
    "        \"repos\": repo_analyses\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YvJ0W1k9B3L"
   },
   "source": [
    "### 3. Newsletter Generation\n",
    "Create formatted email content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5P1t7Zg9B3L"
   },
   "outputs": [],
   "source": [
    "def generate_newsletter(analysis):\n",
    "    \"\"\"Create HTML newsletter with AI insights\"\"\"\n",
    "    \n",
    "    # Generate header\n",
    "    header = \"# ðŸš€ Weekly GenAI Digest\\n\\n\"\n",
    "    \n",
    "    # Top papers section\n",
    "    papers_section = \"## ðŸ“„ Top Research Papers\\n\"\n",
    "    papers_section += \"\\n\".join([f\"- {summary}\" for summary in analysis['papers']])\n",
    "    \n",
    "    # GitHub projects section\n",
    "    repos_section = \"\\n\\n## ðŸ’» Trending Code Repos\\n\"\n",
    "    repos_section += \"\\n\".join([f\"- {analysis}\" for analysis in analysis['repos']])\n",
    "    \n",
    "    # Final assembly\n",
    "    full_content = header + papers_section + repos_section\n",
    "    \n",
    "    # Format with GPT\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Convert this draft into professional newsletter format:\\n{full_content}\"\n",
    "        }],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7oO2-0K9B3M"
   },
   "source": [
    "## Execution Pipeline\n",
    "Run the complete workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vx5vPw3_9B3M"
   },
   "outputs": [],
   "source": [
    "# @title Generate This Week's Issue\n",
    "content = fetch_ai_content()\n",
    "analysis = analyze_content(content)\n",
    "newsletter = generate_newsletter(analysis)\n",
    "\n",
    "print(\"Newsletter Generated!\\n\")\n",
    "print(newsletter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7vj1RSo9B3M"
   },
   "source": [
    "## Email Distribution\n",
    "Send newsletter to subscribers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdOQxq7V9B3M"
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def send_newsletter(recipients):\n",
    "    \"\"\"Distribute via Gmail\"\"\"\n",
    "    \n",
    "    msg = MIMEText(newsletter, 'plain')\n",
    "    msg['Subject'] = 'Your Weekly GenAI Update'\n",
    "    msg['From'] = 'genai-news@yourdomain.com'\n",
    "    msg['To'] = ', '.join(recipients)\n",
    "\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:\n",
    "        server.login('your.email@gmail.com', email_password)\n",
    "        server.sendmail(\n",
    "            msg['From'], recipients, msg.as_string()\n",
    "        )\n",
    "\n",
    "# @title Send Test Email\n",
    "test_recipients = [\"your.email@gmail.com\"]  # Replace with test email\n",
    "send_newsletter(test_recipients)\n",
    "print(\"Newsletter sent successfully!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
